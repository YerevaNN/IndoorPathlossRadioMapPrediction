{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542d9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.extend(['../../IndoorPathlossRadioMapPrediction/'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import imageio.v3 as iio\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "\n",
    "from utils import pad_to_square\n",
    "from algorithm import ICASSP\n",
    "from networks.vit_pp_upernet import ViTPlusPlusUPerNet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79502c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTPlusPlusUPerNet(\n",
       "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (vit_pp): ViTPlusPlus(\n",
       "    (vit): Dinov2Model(\n",
       "      (embeddings): Dinov2Embeddings(\n",
       "        (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "          (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): Dinov2Encoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x Dinov2Layer(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attention): Dinov2Attention(\n",
       "              (attention): Dinov2SelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): Dinov2SelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (layer_scale1): Dinov2LayerScale()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Dinov2MLP(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (layer_scale2): Dinov2LayerScale()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=19, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mixers): ModuleList(\n",
       "    (0-13): 14 x Conv1d(1370, 1369, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (pre_necks): ModuleList(\n",
       "    (0-13): 14 x Linear(in_features=768, out_features=256, bias=True)\n",
       "  )\n",
       "  (neck): StepNeck(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (3-5): 3 x Sequential(\n",
       "        (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (6-8): 3 x Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (9-11): 3 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (12-13): 2 x Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (3-5): 3 x Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (6-8): 3 x Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (9-11): 3 x Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (12-13): 2 x Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (PPN): PSPModule(\n",
       "    (stages): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(258, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): Conv2d(258, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=4)\n",
       "        (1): Conv2d(258, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=7)\n",
       "        (1): Conv2d(258, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): Sequential(\n",
       "      (0): Conv2d(514, 258, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (FPN): FPN_fuse(\n",
       "    (conv1x1): ModuleList(\n",
       "      (0-1): 2 x Conv2d(18, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2-4): 3 x Conv2d(34, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5-7): 3 x Conv2d(66, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (8-10): 3 x Conv2d(130, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (11-12): 2 x Conv2d(258, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (smooth_conv): ModuleList(\n",
       "      (0-12): 13 x Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv_fusion): Sequential(\n",
       "      (0): Conv2d(252, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Conv2d(18, 1, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = ViTPlusPlusUPerNet(\n",
    "    **{\n",
    "        \"image_size\": 518, \n",
    "        \"min_mlp_tokens\": 0, \n",
    "        \"mixer_out\": None, \n",
    "        \"mlp_input_dim\": 19, \n",
    "        \"neck_input_dim\": 256, \n",
    "        \"neck_scales\": [14, 14, 14, 8, 8, 8, 4, 4, 4, 2, 2, 2, 1, 1], \n",
    "        \"neck_size\": [16, 16, 16, 32, 32, 32, 64, 64, 64, 128, 128, 128, 256, 256], \n",
    "        \"num_channels\": 3, \n",
    "        \"num_classes\": 1, \n",
    "        \"pre_out_channels\": None, \n",
    "        \"pretrained\": \"facebook/dinov2-base\", \n",
    "        \"res_hidden_states\": None, \n",
    "        \"up_pool_scales\": [1, 2, 4, 7], \n",
    "        \"use_upernet\": True, \n",
    "        \"v_hidden_size\": 768, \n",
    "        \"v_num_attention_heads\": 12, \n",
    "        \"v_num_channels\": 3, \n",
    "        \"v_num_hidden_layers\": 12, \n",
    "        \"v_patch_size\": 14\n",
    "    }\n",
    ")\n",
    "alg_conf = {\n",
    "    \"fixed_scale\": False, \n",
    "    \"out_norm\": 160,\n",
    "    \"network\": network\n",
    "}\n",
    "alg = ICASSP.load_from_checkpoint(\n",
    "    \"./task1.ckpt\",\n",
    "    **alg_conf\n",
    ")\n",
    "alg.network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356af85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(img, size=518):\n",
    "    orig_size = img.shape[:2]\n",
    "    img = img / np.array([25, 20, 200])\n",
    "    img = pad_to_square(img)\n",
    "    img = resize(img, (size, size))\n",
    "    img = torch.from_numpy(img.astype(np.float32)).permute((2, 0, 1)).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "def get_pred(pred_image, input_img):\n",
    "    mask = np.ones_like(input_img[..., 0])\n",
    "    mask = pad_to_square(mask, fill_value=0).astype(bool)\n",
    "    pred_image = resize(pred_image.squeeze(0).squeeze(0).detach().cpu().numpy(), mask.shape)\n",
    "    pred_image = pred_image[mask].reshape(input_img[..., 0].shape)\n",
    "    pred_image = torch.sigmoid(torch.from_numpy(pred_image)).detach().cpu().numpy()\n",
    "    return pred_image * 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b6aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.02it/s]\n"
     ]
    }
   ],
   "source": [
    "Buildings = range(1, 7)\n",
    "ant_ids = [1]\n",
    "freq = [1]\n",
    "\n",
    "solution = pd.DataFrame()\n",
    "\n",
    "for Antenna_ID in (ant_ids):  \n",
    "    for f_i in  freq:\n",
    "        for b in (Buildings):\n",
    "            for sp in tqdm(range(0, 50), total=50):\n",
    "                image_name = \"B\" + str(b) +  \"_Ant\"+  str(Antenna_ID) + \"_f\"  + str(f_i) + \"_S\" + str(sp)\n",
    "                input_image = iio.imread(\"../ICASSP_TEST_DATA//Inputs/Task_1/\" + image_name + '.png')\n",
    "                your_input_tensor = get_input(input_image)\n",
    "                out = alg.network(your_input_tensor.to(\"cuda:0\"))\n",
    "                y_PL = get_pred(out, input_image) # Note that y_PL should have the same dimensions, W x H,  as the input image\n",
    "                y = Image.fromarray(y_PL).convert(\"RGB\")\n",
    "                y.save(f\"../preds/task1/{image_name}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
